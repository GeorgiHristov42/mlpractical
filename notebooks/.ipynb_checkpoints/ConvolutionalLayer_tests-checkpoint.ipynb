{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below a skeleton class and associated test functions for the `fprop`, `bprop` and `grads_wrt_params` methods of the ConvolutionalLayer class are included.\n",
    "\n",
    "The test functions assume that in your implementation of `fprop` for the convolutional layer, outputs are calculated only for 'valid' overlaps of the kernel filters with the input - i.e. without any padding.\n",
    "\n",
    "It is also assumed that if convolutions with non-unit strides are implemented the default behaviour is to take unit-strides, with the test cases only correct for unit strides in both directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three test functions are defined in the cell below. All the functions take as first argument the *class* corresponding to the convolutional layer implementation to be tested (**not** an instance of the class). It is assumed the class being tested has an `__init__` method with at least all of the arguments defined in the skeleton definition above. A boolean second argument to each function can be used to specify if the layer implements a cross-correlation or convolution based operation (see note in [seventh lecture slides](http://www.inf.ed.ac.uk/teaching/courses/mlp/2016/mlp07-cnn.pdf))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_conv_layer_fprop(layer_class, do_cross_correlation=False):\n",
    "    \"\"\"Tests `fprop` method of a convolutional layer.\n",
    "    \n",
    "    Checks the outputs of `fprop` method for a fixed input against known\n",
    "    reference values for the outputs and raises an AssertionError if\n",
    "    the outputted values are not consistent with the reference values. If\n",
    "    tests are all passed returns True.\n",
    "    \n",
    "    Args:\n",
    "        layer_class: Convolutional layer implementation following the \n",
    "            interface defined in the provided skeleton class.\n",
    "        do_cross_correlation: Whether the layer implements an operation\n",
    "            corresponding to cross-correlation (True) i.e kernels are\n",
    "            not flipped before sliding over inputs, or convolution\n",
    "            (False) with filters being flipped.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: Raised if output of `layer.fprop` is inconsistent \n",
    "            with reference values either in shape or values.\n",
    "    \"\"\"\n",
    "    inputs = np.arange(96).reshape((2, 3, 4, 4))\n",
    "    kernels = np.arange(-12, 12).reshape((2, 3, 2, 2))\n",
    "    if do_cross_correlation:\n",
    "        kernels = kernels[:, :, ::-1, ::-1]\n",
    "    biases = np.arange(2)\n",
    "    true_output = np.array(\n",
    "        [[[[ -958., -1036., -1114.],\n",
    "           [-1270., -1348., -1426.],\n",
    "           [-1582., -1660., -1738.]],\n",
    "          [[ 1707.,  1773.,  1839.],\n",
    "           [ 1971.,  2037.,  2103.],\n",
    "           [ 2235.,  2301.,  2367.]]],\n",
    "         [[[-4702., -4780., -4858.],\n",
    "           [-5014., -5092., -5170.],\n",
    "           [-5326., -5404., -5482.]],\n",
    "          [[ 4875.,  4941.,  5007.],\n",
    "           [ 5139.,  5205.,  5271.],\n",
    "           [ 5403.,  5469.,  5535.]]]]\n",
    "    )\n",
    "    \n",
    "    layer = layer_class(\n",
    "        num_input_channels=kernels.shape[1], \n",
    "        num_output_channels=kernels.shape[0], \n",
    "        input_dim_1=inputs.shape[2], \n",
    "        input_dim_2=inputs.shape[3],\n",
    "        kernel_dim_1=kernels.shape[2],\n",
    "        kernel_dim_2=kernels.shape[3]\n",
    "    )\n",
    "    layer.params = [kernels, biases]\n",
    "    layer_output = layer.fprop(inputs)\n",
    "    \n",
    "    assert layer_output.shape == true_output.shape, (\n",
    "        'Layer fprop gives incorrect shaped output. '\n",
    "        'Correct shape is \\n\\n{0}\\n\\n but returned shape is \\n\\n{1}.'\n",
    "        .format(true_output.shape, layer_output.shape)\n",
    "    )\n",
    "    assert np.allclose(layer_output, true_output), (\n",
    "        'Layer fprop does not give correct output. '\n",
    "        'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}\\n\\n difference is \\n\\n{2}.'\n",
    "        .format(true_output, layer_output, true_output-layer_output)\n",
    "    )\n",
    "    return True\n",
    "\n",
    "def test_conv_layer_bprop(layer_class, do_cross_correlation=False):\n",
    "    \"\"\"Tests `bprop` method of a convolutional layer.\n",
    "    \n",
    "    Checks the outputs of `bprop` method for a fixed input against known\n",
    "    reference values for the gradients with respect to inputs and raises \n",
    "    an AssertionError if the returned values are not consistent with the\n",
    "    reference values. If tests are all passed returns True.\n",
    "    \n",
    "    Args:\n",
    "        layer_class: Convolutional layer implementation following the \n",
    "            interface defined in the provided skeleton class.\n",
    "        do_cross_correlation: Whether the layer implements an operation\n",
    "            corresponding to cross-correlation (True) i.e kernels are\n",
    "            not flipped before sliding over inputs, or convolution\n",
    "            (False) with filters being flipped.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: Raised if output of `layer.bprop` is inconsistent \n",
    "            with reference values either in shape or values.\n",
    "    \"\"\"\n",
    "    inputs = np.arange(96).reshape((2, 3, 4, 4))\n",
    "    kernels = np.arange(-12, 12).reshape((2, 3, 2, 2))\n",
    "    if do_cross_correlation:\n",
    "        kernels = kernels[:, :, ::-1, ::-1]\n",
    "    biases = np.arange(2)\n",
    "    grads_wrt_outputs = np.arange(-20, 16).reshape((2, 2, 3, 3))\n",
    "    outputs = np.array(\n",
    "        [[[[ -958., -1036., -1114.],\n",
    "           [-1270., -1348., -1426.],\n",
    "           [-1582., -1660., -1738.]],\n",
    "          [[ 1707.,  1773.,  1839.],\n",
    "           [ 1971.,  2037.,  2103.],\n",
    "           [ 2235.,  2301.,  2367.]]],\n",
    "         [[[-4702., -4780., -4858.],\n",
    "           [-5014., -5092., -5170.],\n",
    "           [-5326., -5404., -5482.]],\n",
    "          [[ 4875.,  4941.,  5007.],\n",
    "           [ 5139.,  5205.,  5271.],\n",
    "           [ 5403.,  5469.,  5535.]]]]\n",
    "    )\n",
    "    true_grads_wrt_inputs = np.array(\n",
    "      [[[[ 147.,  319.,  305.,  162.],\n",
    "         [ 338.,  716.,  680.,  354.],\n",
    "         [ 290.,  608.,  572.,  294.],\n",
    "         [ 149.,  307.,  285.,  144.]],\n",
    "        [[  23.,   79.,   81.,   54.],\n",
    "         [ 114.,  284.,  280.,  162.],\n",
    "         [ 114.,  272.,  268.,  150.],\n",
    "         [  73.,  163.,  157.,   84.]],\n",
    "        [[-101., -161., -143.,  -54.],\n",
    "         [-110., -148., -120.,  -30.],\n",
    "         [ -62.,  -64.,  -36.,    6.],\n",
    "         [  -3.,   19.,   29.,   24.]]],\n",
    "       [[[  39.,   67.,   53.,   18.],\n",
    "         [  50.,   68.,   32.,   -6.],\n",
    "         [   2.,  -40.,  -76.,  -66.],\n",
    "         [ -31.,  -89., -111.,  -72.]],\n",
    "        [[  59.,  115.,  117.,   54.],\n",
    "         [ 114.,  212.,  208.,   90.],\n",
    "         [ 114.,  200.,  196.,   78.],\n",
    "         [  37.,   55.,   49.,   12.]],\n",
    "        [[  79.,  163.,  181.,   90.],\n",
    "         [ 178.,  356.,  384.,  186.],\n",
    "         [ 226.,  440.,  468.,  222.],\n",
    "         [ 105.,  199.,  209.,   96.]]]])\n",
    "    layer = layer_class(\n",
    "        num_input_channels=kernels.shape[1], \n",
    "        num_output_channels=kernels.shape[0], \n",
    "        input_dim_1=inputs.shape[2], \n",
    "        input_dim_2=inputs.shape[3],\n",
    "        kernel_dim_1=kernels.shape[2],\n",
    "        kernel_dim_2=kernels.shape[3]\n",
    "    )\n",
    "    layer.params = [kernels, biases]\n",
    "    layer_grads_wrt_inputs = layer.bprop(inputs, outputs, grads_wrt_outputs)\n",
    "    assert layer_grads_wrt_inputs.shape == true_grads_wrt_inputs.shape, (\n",
    "        'Layer bprop returns incorrect shaped array. '\n",
    "        'Correct shape is \\n\\n{0}\\n\\n but returned shape is \\n\\n{1}.'\n",
    "        .format(true_grads_wrt_inputs.shape, layer_grads_wrt_inputs.shape)\n",
    "    )\n",
    "    assert np.allclose(layer_grads_wrt_inputs, true_grads_wrt_inputs), (\n",
    "        'Layer bprop does not return correct values. '\n",
    "        'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}\\n\\n difference is \\n\\n{2}'\n",
    "        .format(true_grads_wrt_inputs, layer_grads_wrt_inputs, layer_grads_wrt_inputs-true_grads_wrt_inputs)\n",
    "    )\n",
    "    return True\n",
    "\n",
    "def test_conv_layer_grad_wrt_params(\n",
    "        layer_class, do_cross_correlation=False):\n",
    "    \"\"\"Tests `grad_wrt_params` method of a convolutional layer.\n",
    "    \n",
    "    Checks the outputs of `grad_wrt_params` method for fixed inputs \n",
    "    against known reference values for the gradients with respect to \n",
    "    kernels and biases, and raises an AssertionError if the returned\n",
    "    values are not consistent with the reference values. If tests\n",
    "    are all passed returns True.\n",
    "    \n",
    "    Args:\n",
    "        layer_class: Convolutional layer implementation following the \n",
    "            interface defined in the provided skeleton class.\n",
    "        do_cross_correlation: Whether the layer implements an operation\n",
    "            corresponding to cross-correlation (True) i.e kernels are\n",
    "            not flipped before sliding over inputs, or convolution\n",
    "            (False) with filters being flipped.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: Raised if output of `layer.bprop` is inconsistent \n",
    "            with reference values either in shape or values.\n",
    "    \"\"\"\n",
    "    inputs = np.arange(96).reshape((2, 3, 4, 4))\n",
    "    kernels = np.arange(-12, 12).reshape((2, 3, 2, 2))\n",
    "    biases = np.arange(2)\n",
    "    grads_wrt_outputs = np.arange(-20, 16).reshape((2, 2, 3, 3))\n",
    "    true_kernel_grads = np.array(\n",
    "        [[[[ -240.,  -114.],\n",
    "         [  264.,   390.]],\n",
    "        [[-2256., -2130.],\n",
    "         [-1752., -1626.]],\n",
    "        [[-4272., -4146.],\n",
    "         [-3768., -3642.]]],\n",
    "       [[[ 5268.,  5232.],\n",
    "         [ 5124.,  5088.]],\n",
    "        [[ 5844.,  5808.],\n",
    "         [ 5700.,  5664.]],\n",
    "        [[ 6420.,  6384.],\n",
    "         [ 6276.,  6240.]]]])\n",
    "    if do_cross_correlation:\n",
    "        kernels = kernels[:, :, ::-1, ::-1]\n",
    "        true_kernel_grads = true_kernel_grads[:, :, ::-1, ::-1]\n",
    "    true_bias_grads = np.array([-126.,   36.])\n",
    "    layer = layer_class(\n",
    "        num_input_channels=kernels.shape[1], \n",
    "        num_output_channels=kernels.shape[0], \n",
    "        input_dim_1=inputs.shape[2], \n",
    "        input_dim_2=inputs.shape[3],\n",
    "        kernel_dim_1=kernels.shape[2],\n",
    "        kernel_dim_2=kernels.shape[3]\n",
    "    )\n",
    "    layer.params = [kernels, biases]\n",
    "    layer_kernel_grads, layer_bias_grads = (\n",
    "        layer.grads_wrt_params(inputs, grads_wrt_outputs))\n",
    "    assert layer_kernel_grads.shape == true_kernel_grads.shape, (\n",
    "        'grads_wrt_params gives incorrect shaped kernel gradients output. '\n",
    "        'Correct shape is \\n\\n{0}\\n\\n but returned shape is \\n\\n{1}.'\n",
    "        .format(true_kernel_grads.shape, layer_kernel_grads.shape)\n",
    "    )\n",
    "    assert np.allclose(layer_kernel_grads, true_kernel_grads), (\n",
    "        'grads_wrt_params does not give correct kernel gradients output. '\n",
    "        'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}.'\n",
    "        .format(true_kernel_grads, layer_kernel_grads)\n",
    "    )\n",
    "    assert layer_bias_grads.shape == true_bias_grads.shape, (\n",
    "        'grads_wrt_params gives incorrect shaped bias gradients output. '\n",
    "        'Correct shape is \\n\\n{0}\\n\\n but returned shape is \\n\\n{1}.'\n",
    "        .format(true_bias_grads.shape, layer_bias_grads.shape)\n",
    "    )\n",
    "    assert np.allclose(layer_bias_grads, true_bias_grads), (\n",
    "        'grads_wrt_params does not give correct bias gradients output. '\n",
    "        'Correct output is \\n\\n{0}\\n\\n but returned output is \\n\\n{1}.'\n",
    "        .format(true_bias_grads, layer_bias_grads)\n",
    "    )\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def im2col(A, BSZ, stepsize=1):\n",
    "    # Parameters\n",
    "    m,n = A.shape\n",
    "    s0, s1 = A.strides    \n",
    "    nrows = m-BSZ[0]+1\n",
    "    ncols = n-BSZ[1]+1\n",
    "    shp = BSZ[0],BSZ[1],nrows,ncols\n",
    "    strd = s0,s1,s0,s1\n",
    "    out_view = np.lib.stride_tricks.as_strided(A, shape=shp, strides=strd)\n",
    "    return out_view.reshape(BSZ[0]*BSZ[1],-1)[:,::stepsize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-ba8d24300d3c>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-ba8d24300d3c>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    b = [].reshape(,9)\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def im2col(A, BSZ, stepsize=1):\n",
    "    # Parameters\n",
    "    m,n = A.shape\n",
    "    s0, s1 = A.strides    \n",
    "    nrows = m-BSZ[0]+1\n",
    "    ncols = n-BSZ[1]+1\n",
    "    shp = BSZ[0],BSZ[1],nrows,ncols\n",
    "    strd = s0,s1,s0,s1\n",
    "    out_view = np.lib.stride_tricks.as_strided(A, shape=shp, strides=strd)\n",
    "    return out_view.reshape(BSZ[0]*BSZ[1],-1)[:,::stepsize]\n",
    "\n",
    "import numpy as np\n",
    "test = np.arange(-12, 12).reshape((2, 3, 2, 2))\n",
    "#print(test)\n",
    "p = test.flatten()\n",
    "z = test.flatten().reshape(2,12)\n",
    "\n",
    "x = np.arange(96).reshape((2, 3, 4, 4))\n",
    "\n",
    "created = False\n",
    "\n",
    "b = [].reshape(,9)\n",
    "\n",
    "for image in x:\n",
    "    \n",
    "    for channel in image:\n",
    "        if not created:\n",
    "            bbb = im2col(channel,(2,2))\n",
    "            created = True\n",
    "        else:\n",
    "            ccc = im2col(channel,(2,2))\n",
    "            bbb =np.concatenate((bbb,ccc),axis=0)\n",
    "    \n",
    "print(bbb)\n",
    "#print(z)\n",
    "kernel = np.tile(z,(1,2))\n",
    "print(kernel)\n",
    "output = kernel @ bbb\n",
    "print(output)\n",
    "final_output = output \n",
    "\n",
    "final_final = final_output.reshape(2,3,3)\n",
    "\n",
    "print(final_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of using the test functions if given in the cell below. This assumes you implement a convolution (rather than cross-correlation) operation. If the implementation is correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -9 -10 -11 -12  -5  -6  -7  -8  -1  -2  -3  -4]\n",
      " [  3   2   1   0   7   6   5   4  11  10   9   8]]\n",
      "fprop successful\n",
      "[[ -9 -10 -11 -12  -5  -6  -7  -8  -1  -2  -3  -4]\n",
      " [  3   2   1   0   7   6   5   4  11  10   9   8]]\n",
      "[[[[  0   0   0   0   0]\n",
      "   [  0 -20 -19 -18   0]\n",
      "   [  0 -17 -16 -15   0]\n",
      "   [  0 -14 -13 -12   0]\n",
      "   [  0   0   0   0   0]]\n",
      "\n",
      "  [[  0   0   0   0   0]\n",
      "   [  0 -11 -10  -9   0]\n",
      "   [  0  -8  -7  -6   0]\n",
      "   [  0  -5  -4  -3   0]\n",
      "   [  0   0   0   0   0]]]\n",
      "\n",
      "\n",
      " [[[  0   0   0   0   0]\n",
      "   [  0  -2  -1   0   0]\n",
      "   [  0   1   2   3   0]\n",
      "   [  0   4   5   6   0]\n",
      "   [  0   0   0   0   0]]\n",
      "\n",
      "  [[  0   0   0   0   0]\n",
      "   [  0   7   8   9   0]\n",
      "   [  0  10  11  12   0]\n",
      "   [  0  13  14  15   0]\n",
      "   [  0   0   0   0   0]]]]\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0 -20  -2 -19  -1 -18   0\n",
      "    0   0   0   0 -17   1 -16   2 -15   3   0   0   0   0 -14   4 -13   5\n",
      "  -12   6   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 -11   7 -10   8  -9   9\n",
      "    0   0   0   0  -8  10  -7  11  -6  12   0   0   0   0  -5  13  -4  14\n",
      "   -3  15   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0  147   39\n",
      "   141   33  135   27    0    0    0    0  129   21  123   15  117    9\n",
      "     0    0    0    0  111    3  105   -3   99   -9    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  178   34\n",
      "   170   26  162   18    0    0    0    0  154   10  146    2  138   -6\n",
      "     0    0    0    0  130  -14  122  -22  114  -30    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  209   29\n",
      "   199   19  189    9    0    0    0    0  179   -1  169  -11  159  -21\n",
      "     0    0    0    0  149  -31  139  -41  129  -51    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  240   24\n",
      "   228   12  216    0    0    0    0    0  204  -12  192  -24  180  -36\n",
      "     0    0    0    0  168  -48  156  -60  144  -72    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0   23   59\n",
      "    25   61   27   63    0    0    0    0   29   65   31   67   33   69\n",
      "     0    0    0    0   35   71   37   73   39   75    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0   54   54\n",
      "    54   54   54   54    0    0    0    0   54   54   54   54   54   54\n",
      "     0    0    0    0   54   54   54   54   54   54    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0   85   49\n",
      "    83   47   81   45    0    0    0    0   79   43   77   41   75   39\n",
      "     0    0    0    0   73   37   71   35   69   33    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  116   44\n",
      "   112   40  108   36    0    0    0    0  104   32  100   28   96   24\n",
      "     0    0    0    0   92   20   88   16   84   12    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0 -101   79\n",
      "   -91   89  -81   99    0    0    0    0  -71  109  -61  119  -51  129\n",
      "     0    0    0    0  -41  139  -31  149  -21  159    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  -70   74\n",
      "   -62   82  -54   90    0    0    0    0  -46   98  -38  106  -30  114\n",
      "     0    0    0    0  -22  122  -14  130   -6  138    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  -39   69\n",
      "   -33   75  -27   81    0    0    0    0  -21   87  -15   93   -9   99\n",
      "     0    0    0    0   -3  105    3  111    9  117    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0   -8   64\n",
      "    -4   68    0   72    0    0    0    0    4   76    8   80   12   84\n",
      "     0    0    0    0   16   88   20   92   24   96    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-8bc59ef431c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fprop successful\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbprop_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_conv_layer_bprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvolutionalLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgrads_wrt_param_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_conv_layer_grad_wrt_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvolutionalLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfprop_correct\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgrads_wrt_param_correct\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbprop_correct\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All tests passed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-fc717612b0fc>\u001b[0m in \u001b[0;36mtest_conv_layer_grad_wrt_params\u001b[0;34m(layer_class, do_cross_correlation)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     layer_kernel_grads, layer_bias_grads = (\n\u001b[0;32m--> 206\u001b[0;31m         layer.grads_wrt_params(inputs, grads_wrt_outputs))\n\u001b[0m\u001b[1;32m    207\u001b[0m     assert layer_kernel_grads.shape == true_kernel_grads.shape, (\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m'grads_wrt_params gives incorrect shaped kernel gradients output. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "from mlp.layers import ConvolutionalLayer\n",
    "fprop_correct = test_conv_layer_fprop(ConvolutionalLayer, False)\n",
    "print(\"fprop successful\")\n",
    "bprop_correct = test_conv_layer_bprop(ConvolutionalLayer, True)\n",
    "print(\"bprop successful\")\n",
    "grads_wrt_param_correct = test_conv_layer_grad_wrt_params(ConvolutionalLayer, False)\n",
    "if fprop_correct and grads_wrt_param_correct and bprop_correct:\n",
    "    print('All tests passed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def col2im_indices(cols, x_shape, field_height=3, field_width=3, padding=1,\n",
    "                   stride=1):\n",
    "    \"\"\" An implementation of col2im based on fancy indexing and np.add.at \"\"\"\n",
    "    N, C, H, W = x_shape\n",
    "    H_padded, W_padded = H + 2 * padding, W + 2 * padding\n",
    "    x_padded = np.zeros((N, C, H_padded, W_padded), dtype=cols.dtype)\n",
    "    k, i, j = get_im2col_indices(x_shape, field_height, field_width, padding, stride)\n",
    "    cols_reshaped = cols.reshape(C * field_height * field_width, -1, N)\n",
    "    cols_reshaped = cols_reshaped.transpose(2, 0, 1)\n",
    "    np.add.at(x_padded, (slice(None), k, i, j), cols_reshaped)\n",
    "    if padding == 0:\n",
    "        return x_padded\n",
    "    return x_padded[:, :, padding:-padding, padding:-padding]\n",
    "\n",
    "\n",
    "\n",
    "def get_im2col_indices(x_shape, field_height, field_width, padding=1, stride=1):\n",
    "    # First figure out what the size of the output should be\n",
    "    N, C, H, W = x_shape\n",
    "    assert (H + 2 * padding - field_height) % stride == 0\n",
    "    assert (W + 2 * padding - field_height) % stride == 0\n",
    "    out_height = int((H + 2 * padding - field_height) / stride + 1)\n",
    "    out_width = int((W + 2 * padding - field_width) / stride + 1)\n",
    "\n",
    "    i0 = np.repeat(np.arange(field_height), field_width)\n",
    "    i0 = np.tile(i0, C)\n",
    "    i1 = stride * np.repeat(np.arange(out_height), out_width)\n",
    "    j0 = np.tile(np.arange(field_width), field_height * C)\n",
    "    j1 = stride * np.tile(np.arange(out_width), out_height)\n",
    "    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
    "    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
    "\n",
    "    k = np.repeat(np.arange(C), field_height * field_width).reshape(-1, 1)\n",
    "\n",
    "    return (k.astype(int), i.astype(int), j.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  2,  3,  0],\n",
       "       [ 0,  4,  5,  6,  7,  0],\n",
       "       [ 0,  8,  9, 10, 11,  0],\n",
       "       [ 0, 12, 13, 14, 15,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(16).reshape(4,4)\n",
    "# im = im2col(x,(2,2))\n",
    "# print(im)\n",
    "# col2im_indices(im,(1,1,4,4))\n",
    "\n",
    "np.pad(x,1,'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
